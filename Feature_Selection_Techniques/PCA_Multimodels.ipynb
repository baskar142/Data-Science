{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e55bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f22650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform PCA\n",
    "def perform_pca(X, n_components=6):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1085496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split and scale the dataset\n",
    "def split_and_scale_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6798a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate a classifier\n",
    "def evaluate_classifier(classifier, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Compute confusion matrix, accuracy, and classification report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cae6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train Logistic Regression model\n",
    "def train_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    classifier = LogisticRegression(random_state=0, max_iter=1000)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy, report, cm = evaluate_classifier(classifier, X_test, y_test)\n",
    "    return classifier, accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3c639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train SVM with linear kernel\n",
    "def train_svm_linear(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel='linear', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy, report, cm = evaluate_classifier(classifier, X_test, y_test)\n",
    "    return classifier, accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb97ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train SVM with RBF kernel\n",
    "def train_svm_rbf(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel='rbf', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy, report, cm = evaluate_classifier(classifier, X_test, y_test)\n",
    "    return classifier, accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7f89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train Naive Bayes model\n",
    "def train_naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy, report, cm = evaluate_classifier(classifier, X_test, y_test)\n",
    "    return classifier, accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb5281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train K-Nearest Neighbors model\n",
    "def train_knn(X_train, y_train, X_test, y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy, report, cm = evaluate_classifier(classifier, X_test, y_test)\n",
    "    return classifier, accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b54fd387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train Decision Tree model\n",
    "def train_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy, report, cm = evaluate_classifier(classifier, X_test, y_test)\n",
    "    return classifier, accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a6dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train Random Forest model\n",
    "def train_random_forest(X_train, y_train, X_test, y_test):\n",
    "    classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    accuracy, report, cm = evaluate_classifier(classifier, X_test, y_test)\n",
    "    return classifier, accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b7e69ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.99\n",
      "Confusion Matrix:\n",
      "[[36  0]\n",
      " [ 1 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        36\n",
      "           1       1.00      0.98      0.99        64\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.99      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "\n",
      "Model: SVM Linear\n",
      "Accuracy: 0.99\n",
      "Confusion Matrix:\n",
      "[[36  0]\n",
      " [ 1 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        36\n",
      "           1       1.00      0.98      0.99        64\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.99      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "\n",
      "Model: SVM RBF\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[36  0]\n",
      " [ 0 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "\n",
      "Model: Naive Bayes\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[36  0]\n",
      " [ 0 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[36  0]\n",
      " [ 0 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.99\n",
      "Confusion Matrix:\n",
      "[[36  0]\n",
      " [ 1 63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        36\n",
      "           1       1.00      0.98      0.99        64\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.99      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[36  0]\n",
      " [ 0 64]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "\n",
      "Best Model: SVM RBF\n",
      "Accuracy: 1.0\n",
      "Prediction result: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AB92922\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Main function to process the dataset and train models\n",
    "def main():\n",
    "    # Load dataset and preprocess\n",
    "    dataset = pd.read_csv(\"prep.csv\")\n",
    "    df = pd.get_dummies(dataset, drop_first=True)\n",
    "\n",
    "    X = df.drop('classification_yes', axis=1)\n",
    "    y = df['classification_yes']\n",
    "\n",
    "    # Split and scale the data\n",
    "    X_train, X_test, y_train, y_test, scaler = split_and_scale_data(X, y)\n",
    "\n",
    "    # Perform PCA\n",
    "    X_train_pca, pca = perform_pca(X_train, n_components=6)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Train and evaluate models\n",
    "    models = {\n",
    "        \"Logistic Regression\": train_logistic_regression,\n",
    "        \"SVM Linear\": train_svm_linear,\n",
    "        \"SVM RBF\": train_svm_rbf,\n",
    "        \"Naive Bayes\": train_naive_bayes,\n",
    "        \"K-Nearest Neighbors\": train_knn,\n",
    "        \"Decision Tree\": train_decision_tree,\n",
    "        \"Random Forest\": train_random_forest\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    best_scaler = None\n",
    "\n",
    "    for model_name, train_model in models.items():\n",
    "        classifier, accuracy, report, cm = train_model(X_train_pca, y_train, X_test_pca, y_test)\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Classification Report:\\n{report}\\n\")\n",
    "\n",
    "        # Update the best model if current model has better accuracy\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = classifier\n",
    "            best_model_name = model_name\n",
    "            best_scaler = scaler\n",
    "\n",
    "    print(f\"Best Model: {best_model_name}\")\n",
    "    print(f\"Accuracy: {best_accuracy}\")\n",
    "\n",
    "    # Save the best model, scaler, and PCA transformer\n",
    "    model_filename = f\"finalized_model_{best_model_name.lower().replace(' ', '_')}.sav\"\n",
    "    pickle.dump(best_model, open(model_filename, 'wb'))\n",
    "    pickle.dump(best_scaler, open('scaler.pkl', 'wb'))\n",
    "    pickle.dump(pca, open('pca.pkl', 'wb'))\n",
    "\n",
    "    # Example input for prediction (must match the original feature set)\n",
    "    example_input = [[76.45994832, 3, 0, 148.1126761, 3.077356021, 137.528754, 4.62724359, 12.51815562, 38.86890244, 8408.191126, 4.705597015, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]]\n",
    "\n",
    "    # Scale the example input\n",
    "    example_input_scaled = best_scaler.transform(example_input)\n",
    "\n",
    "    # Apply PCA to the scaled input\n",
    "    example_input_pca = pca.transform(example_input_scaled)\n",
    "\n",
    "    # Load the saved model and make a prediction\n",
    "    loaded_model = pickle.load(open(model_filename, 'rb'))\n",
    "    prediction_result = loaded_model.predict(example_input_pca)\n",
    "    prediction_result = prediction_result.astype(int)\n",
    "\n",
    "    print(\"Prediction result:\", prediction_result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
